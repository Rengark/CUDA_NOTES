### Sauce: https://docs.nvidia.com/cuda/cuda-runtime-api/index.html & slides

### Image for reference
 ![[Pasted image 20250116210725.png]]

# CUDA API
## CUDA API memory functions
### `cudaMalloc`
`cudaError_t cudaMalloc(void** devPtr, size_t size)`
- Allocates an object in the device's **global memory**
- Input Parameters 
	- `void** devPtr`
		- Pointer to the allocated device memory 
			- Its a pointer to a pointer, hence double pointer, do not mistake it for 2D array
	- `size_t size`
		- Requested allocation size in bytes
- Return `cudaError_t`
	- It is to signal the what occurred during the allocation process
		- `cudaSuccess`
			- All went good, nothing wrong
		- `cudaErrorInvalidValue`
			- Indicates that one or more of the parameters passed to the API call is not within an acceptable range of values
		- `cudaErrorMemoryAllocation`
			- API call failed due to being unable to allocate enough memory, or other resources to perform the requested operation. (in this case it should only be related to the lack of memory)
### `cudaMemcpy()`
`cudaError_t cudaMemcpy(void* dst, const void* src, size_t count, cudaMemcpyKind kind)`
- Copies data between host and device
	- Where host is the CPU and it's RAM in most of our cases
	- And the device is the NVIDIA GPU
	- UNLESS OTHERWISE SPECIFIED (by the `kind` input parameter)
- Input Parameters
	- `void* dst` 
		- Destination memory address
	- `const void* src`
		- Source memory address
		- Location is on host, and should not be modified, hence the const
	- `size_t count`
		- The number of bytes to copy
	- `cudaMemcpyKind kind`
		- The type of transfer to do ([[CUDA API Cheatsheet#`enum cudaMemcpyKind`|enum definition]])
- Return `curaError_t`
	- `cudaSuccess`
	- `cudaErrorInvalidValue`
	- `cudaErrorInvalidMemcpyDirection`
	- Refer to the table below. I'm lazy
### `cudaFree`
`cudaError_t cudaFree(void* devPtr)`
- Frees memory on the device (the GPU)
- Input Parameters
	- `void* devPtr`
		- Device pointer (address on device) to memory to free
- Return 
	- `cudaSuccess`
	- `cudaErrorInvalidValue`
### `cudaDeviceSynchronize`
`cudaError_t cudaDeviceSynchronize(void)`
- Waits for compute device to finish
	- Its like `std::thread->join()`, where we wait for the child process to finish
- Input Parameters
	- NONE
- Return
	- `cudaSuccess`
		- Yea, it can't fail :)

## Kernel configuration
Sauce: https://docs.nvidia.com/cuda/cuda-c-programming-guide/#execution-configuration
General format of invocation & configuration:
`KernelFunction<<<Dg, Db, Ns, S>>>(...args...)`
- The kernel function is generally **whatever function each "thread" is going to run**
- The above configuration is how we tell the GPU the dimension of the grid and blocks that will be used to execute the function on the device itself
- ### [[CUDA API Cheatsheet#Blocks, Grids, Threads|Block, Grid, etc. explanation]]
- Config Parameters:
	- `Dg` 
		- Of type `dim3`
		- It specifies the dimension and size of the grid, such that `Dg.x * Dg.y * Dg.z` equals the number of blocks being launched
	- `Db` 
		- Of type `dim3` 
		- Specifies the dimension and size of each block, such that `Db.x * Db.y * Db.z` equals the number of threads per block
	- `Ns`
		-  Of type `size_t` 
		- Specifies the number of bytes in shared memory that is dynamically allocated per block for this call in addition to the statically allocated memory; this dynamically allocated memory is used by any of the variables declared as an external array as mentioned in [__shared__](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#shared)
		- `Ns` is an optional argument which defaults to 0
	- `S` 
		- Of type `cudaStream_t` 
		- Specifies the associated stream
		- `S` is an optional argument which defaults to 0.

## Inside a Kernel
*I'm thinking of popcorn now...*
This function is lifted from my A1 solution
```c++
__global__  void heatDistrCalc(float* in, float* out, uint nRowPoints)
{
	uint i = blockIdx.y * blockDim.y + threadIdx.y;
	uint j = blockIdx.x * blockDim.x + threadIdx.x;

	if (i < nRowPoints - 1 && j < nRowPoints - 1 && i >0 && j >0)
	{
		out[i * nRowPoints + j] = 0.25f * (in[(i - 1) * nRowPoints + j] + in[(i + 1) * nRowPoints + j] + in[i * nRowPoints + j - 1] + in[i * nRowPoints + j + 1]);
	}
}
```
- Each block within the grid can be identified by a one-dimensional, two-dimensional, or three-dimensional index (it is unique)
- It is accessible within each kernel (the function itself) via the built-in variable:
	- `blockIdx`
- Next if we want to access the dimension of the thread block:
	- `blockDim`
	-  Remember, the block is multi dimensional! hence that is why we need to multiply the y-dimension with the block index itself so that we arrive at the correct location in memory
		- Try to think of it as like regular 2 dimensional arrays, we usually follow the format:
			- `arr[y * i + x]` to access the value in the `arr[y][x]` location for e.g.
			- Same idea here
- Lastly the thread index, after arriving at the correct block of threads we want to offset to the correct location within the block. We can use:
	- `threadIdx`
# Additional notes
Welcome to the really boring shit
### [CUDA Refresher](https://developer.nvidia.com/blog/cuda-refresher-cuda-programming-model/)
- If you don't get any of the terminology go there ^
## Blocks, Grids, Threads
![[gpus-in-blocks-625x203.png]]
*note, the squiggly lines in each block is a thread, if that isn't obvious*
- A group of **threads** is called a **CUDA block**
- **CUDA blocks** are grouped into a **grid**
- A **kernel** is executed as a **grid** of **blocks** of **threads**
- Top down:
	- Grid (GPU) -> Block (Stream processor) -> Thread (Kernels)
- Extra nerdy shit (I don't think we need to know this explicitly)
	- Each CUDA block is executed by one streaming multiprocessor (SM)
	- One SM can run several concurrent CUDA blocks depending on the resources needed by each block.
	- Each kernel is executed on one device
		- CUDA supports running **MULTIPLE KERNELS** on one device at one time

## `enum cudaMemcpyKind`

Usually, to my knowledge Host = CPU, device = GPU.
There can easily be multiple GPU's in a given system, so the device->device transfer mode makes sense.

| Ordinal Index | Value                      | Operation                                                                                                                     |
| ------------- | -------------------------- | ----------------------------------------------------------------------------------------------------------------------------- |
| 0             | `cudaMemcpyHostToHost`     | Host -> Host                                                                                                                  |
| 1             | `cudaMemcpyHostToDevice`   | Host -> Device                                                                                                                |
| 2             | `cudaMemcpyDeviceToHost`   | Device -> Host                                                                                                                |
| 3             | `cudaMemcpyDeviceToDevice` | Device -> Device                                                                                                              |
| 4             | `cudaMemcpyDefault`        | Direction of the transfer is **inferred** from the pointer values. Requires unified virtual addressing (it figures it out <3) |

## `enum cudaError`
This shit long as hell, if its wrong blame GPT LOL

| Ordinal Index | Value                             | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |
| ------------- | --------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `0` | `cudaSuccess`                     | The API call returned with no errors. In the case of query calls, this also means that the operation being queried is complete (see [cudaEventQuery()](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EVENT.html#group__CUDART__EVENT_1g2bf738909b4a059023537eaa29d8a5b7 "Queries an event's status.") and [cudaStreamQuery()](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g2021adeb17905c7ec2a3c1bf125c5435 "Queries an asynchronous stream for completion status.")).                                                                                                     |
| `1` | `cudaErrorInvalidValue`           | This indicates that one or more of the parameters passed to the API call is not within an acceptable range of values.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |
| `2` | `cudaErrorMemoryAllocation`       | The API call failed because it was unable to allocate enough memory or other resources to perform the requested operation.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| `3` | `cudaErrorInitializationError`    | The API call failed because the CUDA driver and runtime could not be initialized.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |
| `4` | `cudaErrorCudartUnloading`        | This indicates that a CUDA Runtime API call cannot be executed because it is being called during process shut down, at a point in time after CUDA driver has been unloaded.                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |
| `5` | `cudaErrorProfilerDisabled`       | This indicates profiler is not initialized for this run. This can happen when the application is running with external profiling tools like visual profiler.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |
| `6` | `cudaErrorProfilerNotInitialized` | [Deprecated](https://docs.nvidia.com/cuda/cuda-runtime-api/deprecated.html#deprecated__deprecated_1_deprecated000052)<br><br>This error return is deprecated as of CUDA 5.0. It is no longer an error to attempt to enable/disable the profiling via [cudaProfilerStart](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__PROFILER.html#group__CUDART__PROFILER_1gf536d75bb382356e10e3b4e89f4a5374 "Enable profiling.") or [cudaProfilerStop](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__PROFILER.html#group__CUDART__PROFILER_1g826922d9d1d0090d4a9a6b8b249cebb5 "Disable profiling.") without initialization. |
| `7` | `cudaErrorProfilerAlreadyStarted` |  [Deprecated](https://docs.nvidia.com/cuda/cuda-runtime-api/deprecated.html#deprecated__deprecated_1_deprecated000053)<br><br>This error return is deprecated as of CUDA 5.0. It is no longer an error to call [cudaProfilerStart()](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__PROFILER.html#group__CUDART__PROFILER_1gf536d75bb382356e10e3b4e89f4a5374 "Enable profiling.") when profiling is already enabled.                                                                                                                                                                                                      |
| `8` | `cudaErrorProfilerAlreadyStopped` |  [Deprecated](https://docs.nvidia.com/cuda/cuda-runtime-api/deprecated.html#deprecated__deprecated_1_deprecated000054)<br><br>This error return is deprecated as of CUDA 5.0. It is no longer an error to call [cudaProfilerStop()](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__PROFILER.html#group__CUDART__PROFILER_1g826922d9d1d0090d4a9a6b8b249cebb5 "Disable profiling.") when profiling is already disabled.                                                                                                                                                                                                     |
| `9` | `cudaErrorInvalidConfiguration`   | This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requesting more shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks. See [cudaDeviceProp](https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp) for more device limitations.                                                                                                                                                                                                                                       |
| `12` | `cudaErrorInvalidPitchValue`      | This indicates that one or more of the pitch-related parameters passed to the API call is not within the acceptable range for pitch.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
| `13` | `cudaErrorInvalidSymbol`          | This indicates that the symbol name/identifier passed to the API call is not a valid name or identifier.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |
| `16` | `cudaErrorInvalidHostPointer`     | [Deprecated](https://docs.nvidia.com/cuda/cuda-runtime-api/deprecated.html#deprecated__deprecated_1_deprecated000055) - This error return is deprecated as of CUDA 10.1. This indicates that at least one host pointer passed to the API call is not a valid host pointer.                                                                                                                                                                                                                                                                                                                                                                    |
| `17` | `cudaErrorInvalidDevicePointer`   | [Deprecated](https://docs.nvidia.com/cuda/cuda-runtime-api/deprecated.html#deprecated__deprecated_1_deprecated000056) - This error return is deprecated as of CUDA 10.1. This indicates that at least one device pointer passed to the API call is not a valid device pointer.                                                                                                                                                                                                                                                                                                                                                                |
| `18` | `cudaErrorInvalidTexture`         | This indicates that the texture passed to the API call is not a valid texture.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |
| `19` | `cudaErrorInvalidTextureBinding`  | This indicates that the texture binding is not valid. This occurs if you call `cudaGetTextureAlignmentOffset()` with an unbound texture.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |
| `20` | `cudaErrorInvalidChannelDescriptor` | This indicates that the channel descriptor passed to the API call is not valid. This occurs if the format is not one of the formats specified by [cudaChannelFormatKind](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g8085eac5cb54b4228f3619a60f235119), or if one of the dimensions is invalid. |
| `21` | `cudaErrorInvalidMemcpyDirection`   | This indicates that the direction of the memcpy passed to the API call is not one of the types specified by [cudaMemcpyKind](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g18fa99055ee694244a270e4d5101e95b). |
| `22` | `cudaErrorAddressOfConstant`        | [Deprecated](https://docs.nvidia.com/cuda/cuda-runtime-api/deprecated.html#deprecated__deprecated_1_deprecated000057) - This error return is deprecated as of CUDA 3.1. Variables in constant memory may now have their address taken by the runtime via [cudaGetSymbolAddress()](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g4f513be54d3794667c2017146b3d6a2b). This indicated that the user has taken the address of a constant variable, which was forbidden up until the CUDA 3.1 release. |
| `23` | `cudaErrorTextureFetchFailed`       | [Deprecated](https://docs.nvidia.com/cuda/cuda-runtime-api/deprecated.html#deprecated__deprecated_1_deprecated000058) - This error return is deprecated as of CUDA 3.1. Device emulation mode was removed with the CUDA 3.1 release. This indicated that a texture fetch was not able to be performed. This was previously used for device emulation of texture operations. |
| `24` | `cudaErrorTextureNotBound`          | [Deprecated](https://docs.nvidia.com/cuda/cuda-runtime-api/deprecated.html#deprecated__deprecated_1_deprecated000059) - This error return is deprecated as of CUDA 3.1. Device emulation mode was removed with the CUDA 3.1 release. This indicated that a texture was not bound for access. This was previously used for device emulation of texture operations. |
| `25` | `cudaErrorSynchronizationError`     | [Deprecated](https://docs.nvidia.com/cuda/cuda-runtime-api/deprecated.html#deprecated__deprecated_1_deprecated000060) - This error return is deprecated as of CUDA 3.1. Device emulation mode was removed with the CUDA 3.1 release. This indicated that a synchronization operation had failed. This was previously used for some device emulation functions. |
| `26` | `cudaErrorInvalidFilterSetting`     | This indicates that a non-float texture was being accessed with linear filtering. This is not supported by CUDA.                                                                                                                                |
| `27` | `cudaErrorInvalidNormSetting`       | This indicates that an attempt was made to read a non-float texture as a normalized float. This is not supported by CUDA.                                                                                                                         |
| `28` | `cudaErrorMixedDeviceExecution`     | [Deprecated](https://docs.nvidia.com/cuda/cuda-runtime-api/deprecated.html#deprecated__deprecated_1_deprecated000061) - This error return is deprecated as of CUDA 3.1. Device emulation mode was removed with the CUDA 3.1 release. Mixing of device and device emulation code was not allowed. |
| `31` | `cudaErrorNotYetImplemented`        | [Deprecated](https://docs.nvidia.com/cuda/cuda-runtime-api/deprecated.html#deprecated__deprecated_1_deprecated000062) - This error return is deprecated as of CUDA 4.1. This indicates that the API call is not yet implemented. Production releases of CUDA will never return this error. |
| `32` | `cudaErrorMemoryValueTooLarge`      | [Deprecated](https://docs.nvidia.com/cuda/cuda-runtime-api/deprecated.html#deprecated__deprecated_1_deprecated000063) - This error return is deprecated as of CUDA 3.1. Device emulation mode was removed with the CUDA 3.1 release. This indicated that an emulated device pointer exceeded the 32-bit address range.                                                     |
| `34` | `cudaErrorStubLibrary`              | This indicates that the CUDA driver that the application has loaded is a stub library. Applications running with the stub rather than a real driver loaded will result in CUDA API returning this error.                                          |
| `35` | `cudaErrorInsufficientDriver`       | This indicates that the installed NVIDIA CUDA driver is older than the CUDA runtime library. This is not a supported configuration. Users should install an updated NVIDIA display driver to allow the application to run.                        |
| `36` | `cudaErrorCallRequiresNewerDriver`  | This indicates that the API call requires a newer CUDA driver than the one currently installed. Users should install an updated NVIDIA CUDA driver to allow the API call to succeed.                                                             |
| `37` | `cudaErrorInvalidSurface`           | This indicates that the surface passed to the API call is not a valid surface.                                                                                                                                                                    |
| `43` | `cudaErrorDuplicateVariableName`    | This indicates that multiple global or constant variables (across separate CUDA source files in the application) share the same string name.                                                                                                     |
| `44` | `cudaErrorDuplicateTextureName`     | This indicates that multiple textures (across separate CUDA source files in the application) share the same string name.                                                                                                                         |
| `45` | `cudaErrorDuplicateSurfaceName`     | This indicates that multiple surfaces (across separate CUDA source files in the application) share the same string name.                                                                                                                         |
| `46` | `cudaErrorDevicesUnavailable`       | This indicates that all CUDA devices are busy or unavailable at the current time. Devices may be unavailable due to [cudaComputeModeProhibited](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg7eb25f5413a962faad0956d92bae10d0fc71b88518e4501544d6e65b5f3671b6), [cudaComputeModeExclusiveProcess](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg7eb25f5413a962faad0956d92bae10d02cd032834fecbec513ea1018145b111d), long-running CUDA kernels, or memory constraints on a device already performing active CUDA work. |
| `49` | `cudaErrorIncompatibleDriverContext`| This indicates that the current context is not compatible with the CUDA Runtime. This can occur when using CUDA Runtime/Driver interoperability and the Driver context is incompatible due to reasons like API version mismatch, non-primary context, or context destruction. See [Interactions](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DRIVER.html#group__CUDART__DRIVER) for more information. |
| `52` | `cudaErrorMissingConfiguration`     | The device function being invoked (usually via [cudaLaunchKernel()](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EXECUTION.html#group__CUDART__EXECUTION_1g5064cdf5d8e6741ace56fd8be951783c "Launches a device function.")) was not previously configured via the cudaConfigureCall() function.|
| `53` | `cudaErrorPriorLaunchFailure`                   | [Deprecated](https://docs.nvidia.com/cuda/cuda-runtime-api/deprecated.html#deprecated__deprecated_1_deprecated000064) This error return is deprecated as of CUDA 3.1. Device emulation mode was removed with the CUDA 3.1 release. This indicated that a previous kernel launch failed. This was previously used for device emulation of kernel launches.                                                                                                                                                                                                                                                                                                                                                                 |
| `65` | `cudaErrorLaunchMaxDepthExceeded`               | This error indicates that a device runtime grid launch did not occur because the depth of the child grid would exceed the maximum supported number of nested grid launches.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |
| `66` | `cudaErrorLaunchFileScopedTex`                  | This error indicates that a grid launch did not occur because the kernel uses file-scoped textures which are unsupported by the device runtime. Kernels launched via the device runtime only support textures created with the Texture Object API's.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |
| `67` | `cudaErrorLaunchFileScopedSurf`                 | This error indicates that a grid launch did not occur because the kernel uses file-scoped surfaces which are unsupported by the device runtime. Kernels launched via the device runtime only support surfaces created with the Surface Object API's.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |
| `68` | `cudaErrorSyncDepthExceeded`                    | This error indicates that a call to [cudaDeviceSynchronize](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g10e20b05a95f638a4071a655503df25d "Wait for compute device to finish.") made from the device runtime failed because the call was made at grid depth greater than either the default (2 levels of grids) or the user-specified device limit [cudaLimitDevRuntimeSyncDepth](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg4c4b34c054d383b0e9a63ab0ffc9365123c4900be4af436cb769e4c72d07be11). Additional levels of sync depth require the runtime to reserve large amounts of device memory.                                                                                                                                                                                                                       |
| `69` | `cudaErrorLaunchPendingCountExceeded`           | This error indicates that a device runtime grid launch failed because the launch would exceed the limit [cudaLimitDevRuntimePendingLaunchCount](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg4c4b34c054d383b0e9a63ab0ffc9365118712cb05d2c3efaeea73afba823d916). For this launch to proceed successfully, [cudaDeviceSetLimit](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g05956f16eaa47ef3a4efee84563ccb7d "Set resource limits.") must be called. Raising this limit requires reserving additional device memory.                                                                                                                                                                                                                               |
| `98` | `cudaErrorInvalidDeviceFunction`                | The requested device function does not exist or is not compiled for the proper device architecture.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
| `100`| `cudaErrorNoDevice`                             | This indicates that no CUDA-capable devices were detected by the installed CUDA driver.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |
| `101`| `cudaErrorInvalidDevice`                        | This indicates that the device ordinal supplied by the user does not correspond to a valid CUDA device or that the action requested is invalid for the specified device.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |
| `102`| `cudaErrorDeviceNotLicensed`                    | This indicates that the device doesn't have a valid Grid License.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |
| `103`| `cudaErrorSoftwareValidityNotEstablished`       | By default, the CUDA runtime may perform a minimal set of self-tests, as well as CUDA driver tests, to establish the validity of both. Introduced in CUDA 11.2, this error return indicates that at least one of these tests has failed and the validity of either the runtime or the driver could not be established.                                                                                                                                                                                                                                                                                                                                                                                                                                         |
| `127`| `cudaErrorStartupFailure`                       | This indicates an internal startup failure in the CUDA runtime.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |
| `200`| `cudaErrorInvalidKernelImage`                   | This indicates that the device kernel image is invalid.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |
| `201` | `cudaErrorDeviceUninitialized`          | This frequently indicates that there is no context bound to the current thread or the context passed to an API call is not valid (such as a destroyed context).                                         |
| `205` | `cudaErrorMapBufferObjectFailed`        | This indicates that the buffer object could not be mapped.                                                                                                                                             |
| `206` | `cudaErrorUnmapBufferObjectFailed`      | This indicates that the buffer object could not be unmapped.                                                                                                                                           |
| `207` | `cudaErrorArrayIsMapped`                | This indicates that the specified array is currently mapped and cannot be destroyed.                                                                                                                   |
| `208` | `cudaErrorAlreadyMapped`                | This indicates that the resource is already mapped.                                                                                                                                                    |
| `209` | `cudaErrorNoKernelImageForDevice`       | This indicates that there is no kernel image available suitable for the device. Occurs when code generation options do not include the proper device configuration.                                    |
| `210` | `cudaErrorAlreadyAcquired`              | This indicates that a resource has already been acquired.                                                                                                                                             |
| `211` | `cudaErrorNotMapped`                    | This indicates that a resource is not mapped.                                                                                                                                                          |
| `212` | `cudaErrorNotMappedAsArray`             | This indicates that a mapped resource is not available for access as an array.                                                                                                                       |
| `213` | `cudaErrorNotMappedAsPointer`           | This indicates that a mapped resource is not available for access as a pointer.                                                                                                                     |
| `214` | `cudaErrorECCUncorrectable`             | This indicates that an uncorrectable ECC error was detected during execution.                                                                                                                        |
| `215` | `cudaErrorUnsupportedLimit`             | This indicates that the `cudaLimit` passed to the API call is not supported by the active device.                                                                                                      |
| `216` | `cudaErrorDeviceAlreadyInUse`           | This indicates that a call tried to access an exclusive-thread device that is already in use by a different thread.                                                                                   |
| `217` | `cudaErrorPeerAccessUnsupported`        | This indicates that P2P (peer-to-peer) access is not supported across the given devices.                                                                                                               |
| `218` | `cudaErrorInvalidPtx`                   | A PTX compilation failed. The runtime may fall back to compiling PTX if an application does not contain a suitable binary for the current device.                                                     |
| `219` | `cudaErrorInvalidGraphicsContext`       | This indicates an error with the OpenGL or DirectX context.                                                                                                                                           |
| `220` | `cudaErrorNvlinkUncorrectable`          | This indicates that an uncorrectable NVLink error was detected during execution.                                                                                                                     |
| `221` | `cudaErrorJitCompilerNotFound`          | This indicates that the PTX JIT compiler library was not found.                                                                                                                                       |
| `222` | `cudaErrorUnsupportedPtxVersion`        | This indicates that the provided PTX was compiled with an unsupported toolchain, such as a newer compiler version not supported by the CUDA driver.                                                    |
| `223` | `cudaErrorJitCompilationDisabled`       | This indicates that JIT (Just-in-Time) compilation was disabled. The runtime may fall back to compiling PTX if no suitable binary is available for the device.                                          |
| `224` | `cudaErrorUnsupportedExecAffinity`      | This indicates that the provided execution affinity is not supported by the device.                                                                                                                  |
| `225` | `cudaErrorUnsupportedDevSideSync`       | This indicates that the code to be compiled by the PTX JIT contains unsupported calls to `cudaDeviceSynchronize`.                                                                                      |
| `300` | `cudaErrorInvalidSource`                | This indicates that the device kernel source is invalid.                                                                                                                                               |
| `301` | `cudaErrorFileNotFound`                 | This indicates that the file specified was not found.                                                                                                                                                 |
| `302` | `cudaErrorSharedObjectSymbolNotFound`   | This indicates that a link to a shared object failed to resolve.                                                                                                                                       |
| `303` | `cudaErrorSharedObjectInitFailed`       | This indicates that initialization of a shared object failed.                                                                                                                                         |
| `304` | `cudaErrorOperatingSystem`              | This error indicates that an OS call failed.                                                                                                                                                           |
| `400` | `cudaErrorInvalidResourceHandle`        | This indicates that a resource handle passed to the API call was not valid. Resource handles are opaque types like `cudaStream_t` and `cudaEvent_t`.                                                   |
| `401  | `cudaErrorIllegalState`                 | This indicates that a resource required by the API call is not in a valid state to perform the requested operation.                                                                                   |
| `402` | `cudaErrorLossyQuery`                   | This indicates an attempt was made to introspect an object in a way that discards important information. Occurs when the API version doesn’t support the object.                                        |
| `500` | `cudaErrorSymbolNotFound`               | This indicates that a named symbol was not found, such as global/constant variable names, driver function names, texture names, or surface names.                                                       |
| `600` | `cudaErrorNotReady`                     | This indicates that asynchronous operations issued previously have not completed yet. This is not an error but must be distinguished from `cudaSuccess`.                                               |
| `700` | `cudaErrorIllegalAddress`               | The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistent state and must be terminated and relaunched.                               |
| `701` | `cudaErrorLaunchOutOfResources`         | This indicates that a kernel launch did not occur because there were insufficient resources, such as too many arguments or an over-specified number of threads.                                         |
| `702` | `cudaErrorLaunchTimeout`                | This indicates that the device kernel took too long to execute. This can only occur if timeouts are enabled on the device.                                                                            |
| `703` | `cudaErrorLaunchIncompatibleTexturing`  | This error indicates that the kernel launch uses an incompatible texturing mode.                                                                                                                     |
| `704` | `cudaErrorLaunchOutOfResources`         | This indicates that a kernel launch did not occur due to insufficient resources, such as too many threads or arguments.                                                                                 |
| `705` | `cudaErrorLaunchFailure`                | This indicates a kernel launch failure, typically related to the launch configuration or resource issues.                                                                                               |
| `706` | `cudaErrorPriorLaunchFailure`           | This indicates that a previous launch has failed, preventing the current one from launching.                                                                                                             |
| `707` | `cudaErrorInvalidDeviceFunction`        | This error occurs when an invalid device function is launched.                                                                                                                                        |
| `708` | `cudaErrorInvalidConfiguration`         | This error occurs when an invalid kernel launch configuration is passed (e.g., an invalid number of blocks or threads).                                                                                 |
| `709` | `cudaErrorInvalidDevicePointer`         | This indicates an invalid device pointer has been provided.                                                                                                                                           |
| `710` | `cudaErrorInvalidMemcpyDirection`       | This indicates an invalid memory copy direction (e.g., copying between device and host with an incompatible direction).                                                                                 |
| `711` | `cudaErrorAddressOfConstant`            | This error occurs when an address of a constant variable is used in an unsupported manner.                                                                                                               |
| `712` | `cudaErrorTextureFetchFailed`           | This error occurs when a texture fetch operation fails.                                                                                                                                               |
| `713` | `cudaErrorTextureNotBound`              | This error occurs when a texture reference is not bound to any resource.                                                                                                                               |
| `714` | `cudaErrorSynchronizationError`         | This error occurs when a synchronization operation fails.                                                                                                                                             |
| `715` | `cudaErrorInvalidFilterSetting`         | This indicates an invalid filter setting when performing texture fetching.                                                                                                                              |
| `716` | `cudaErrorInvalidNormSetting`           | This indicates an invalid norm setting when performing texture fetching.                                                                                                                                |
| `717` | `cudaErrorMixedDeviceExecution`         | This error occurs when mixed device execution (e.g., using different GPU models in the same operation) is attempted and not supported.                                                                   |
| `718` | `cudaErrorCudartUnloading`              | This error occurs when the CUDA runtime library is being unloaded while there are still active kernels running.                                                                                        |
| `719` | `cudaErrorProfilingTooManyEvents`       | This error occurs when there are too many profiling events being registered.                                                                                                                            |
| `720` | `cudaErrorTooManyPeers`                 | This error occurs when the maximum number of peer devices has been exceeded.                                                                                                                            |
| `721` | `cudaErrorHostMemoryAlreadyRegistered`  | This error occurs when the host memory is already registered with the CUDA driver and cannot be registered again.                                                                                       |
| `722` | `cudaErrorHostMemoryNotRegistered`      | This error occurs when the host memory has not been registered with the CUDA driver but was expected to be.                                                                                             |
| `723` | `cudaErrorOperatingSystemError`         | This error occurs when there is an OS-specific error in managing memory or devices.                                                                                                                     |
| `724` | `cudaErrorSharedObjectSymbolNotFound`   | This error occurs when the symbol in a shared object is not found.                                                                                                                                     |
| `725` | `cudaErrorUnimplementedFunction`        | This error indicates that a function is not implemented for the requested operation.                                                                                                                     |
| `726` | `cudaErrorUnsupportedFunctionality`     | This error indicates that a requested functionality is not supported.                                                                                                                                  |
| `727` | `cudaErrorFunctionNotYetImplemented`    | This indicates that a function has not yet been implemented for the requested platform or architecture.                                                                                                 |
| `728` | `cudaErrorInvalidDeviceFunction`        | This error occurs when an invalid device function is used.                                                                                                                                             |
| `729` | `cudaErrorInvalidConfiguration`         | This indicates that a kernel launch configuration is invalid.                                                                                                                                         |
| `730` | `cudaErrorInvalidDevicePointer`         | This indicates that an invalid device pointer was encountered.                                                                                                                                         |
| `731` | `cudaErrorOutOfMemory`                  | This indicates that there was insufficient memory available on the device.                                                                                                                             |
| `732` | `cudaErrorNoDevice`                     | This indicates that no CUDA-capable devices were found.                                                                                                                                               |
| `733` | `cudaErrorInvalidDevice`                | This indicates an invalid CUDA device.                                                                                                                                                                |
| `734` | `cudaErrorSetOnActive`                  | This indicates an invalid set operation has been attempted on a device in an active context.                                                                                                            |
| `735` | `cudaErrorDeviceAlreadyInUse`           | This indicates that a CUDA device is already in use and cannot be used simultaneously by another thread.                                                                                               |
| `736` | `cudaErrorIncompatibleDeviceContext`    | This error occurs when a device context is incompatible with the target device.                                                                                                                          |
| `737` | `cudaErrorUnsupportedFeature`           | This indicates that the requested feature is not supported on the current device.                                                                                                                      |
| `738` | `cudaErrorInvalidTexture`               | This indicates that an invalid texture has been used in a kernel launch.                                                                                                                               |
| `739` | `cudaErrorInvalidSurface`               | This indicates that an invalid surface has been used in a kernel launch.                                                                                                                               |
| `740` | `cudaErrorMemoryAllocationFailure`      | This error occurs when a memory allocation on the device has failed.                                                                                                                                   |
| `741` | `cudaErrorNotMappedAsPointer`           | This indicates that the mapped resource is not available for access as a pointer.                                                                                                                     |
| `742` | `cudaErrorPeerAccess`                   | This indicates a peer-to-peer access error.                                                                                                                                                           |
| `743` | `cudaErrorSharedMemory`                 | This error occurs when a shared memory access failure occurs.                                                                                                                                          |
| `744` | `cudaErrorUnifiedMemoryAccess`          | This error occurs when there is an issue with accessing unified memory.                                                                                                                                 |
| `745` | `cudaErrorLaunchIncompatible`           | This error occurs when the kernel launch is incompatible with the current configuration.                                                                                                                 |
| `746` | `cudaErrorThreadSynchronizeTimeout`     | This indicates a thread synchronization timeout.                                                                                                                                                      |
| `747` | `cudaErrorTimeout`                      | This error occurs when a timeout occurs during execution of a kernel.                                                                                                                                  |
| `748` | `cudaErrorInvalidPTX`                   | This error indicates that there was a problem with PTX (parallel thread execution) processing.                                                                                                         |
| `749` | `cudaErrorUnknown`                      | This is a generic error indicating an unknown problem occurred.                                                                                                                                       |
| `750` | `cudaErrorFailure`                      | This indicates a failure in CUDA operations, often used as a fallback error.                                                                                                                           |
| `751` | `cudaErrorMemoryUnavailable`            | This error occurs when memory is unavailable for the requested operation.                                                                                                                             |
| `752` | `cudaErrorInvalidAddress`               | This error occurs when an invalid address is used in memory operations.                                                                                                                                 |
| `753` | `cudaErrorUnknownMemoryError`           | This indicates an unknown error in memory allocation.                                                                                                                                                 |
| `754` | `cudaErrorDeviceNotFound`               | This indicates that no CUDA-compatible device was found.                                                                                                                                              |
| `755` | `cudaErrorNoKernelImageForDevice`       | This error occurs when there is no kernel image for the specified device.                                                                                                                              |
| `756` | `cudaErrorInvalidFunction`              | This error occurs when an invalid CUDA function is called.                                                                                                                                             |
| `1000` | `cudaErrorAPIError`                     | This indicates that an API error occurred in the system.                                                                                                                                               |









